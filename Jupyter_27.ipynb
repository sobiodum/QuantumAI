{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/floriankockler/anaconda3/envs/py310/lib/python3.10/site-packages/pyfolio/pos.py:25: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna, joblib, matplotlib, os, pyfolio, sys\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from pyfolio import timeseries\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "from QuantumAI.config import config\n",
    "from QuantumAI.config import config_tickers\n",
    "from QuantumAI.preprocessors.yahoodownloader import YahooDownloader\n",
    "from QuantumAI.preprocessors.preprocessors import FeatureEngineer, data_split\n",
    "# from QuantumAI.env.env_portfolio import StockPortfolioEnv\n",
    "# from QuantumAI.env.env_portfolioSPX import StockPortfolioEnv\n",
    "from QuantumAI.env.env_portfolio_original import StockPortfolioEnv\n",
    "from QuantumAI.env.env_portfolioSPXvsCash import SPXvsCASH\n",
    "from QuantumAI.models.models import DRLAgent\n",
    "from QuantumAI.plot.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts, show_weight_distribution\n",
    "from QuantumAI.preprocessors.data_processor import DataProcessor\n",
    "from QuantumAI.preprocessors.processor_yahoofinance import YahooFinanceProcessor\n",
    "from QuantumAI.hyper_opt.hyperopt1 import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbg_full_start_date=\"1991-01-02\"\n",
    "full_end_date=\"2023-07-25\"\n",
    "bbg_train_start_date=\"1991-01-02\"\n",
    "bbg_train_end_date=\"2015-12-31\"\n",
    "bbg_validate_start_date=\"2016-01-01\"\n",
    "bbg_validate_end_date=\"2020-12-31\"\n",
    "bbg_test_start_date=\"2021-01-01\"\n",
    "bbg_test_end_date=\"2023-07-25\"\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_pickle(\"pickle.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_split(df, bbg_train_start_date, bbg_train_end_date)\n",
    "validate = data_split(df, bbg_validate_start_date, bbg_validate_end_date)\n",
    "test = data_split(df, bbg_test_start_date, bbg_test_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 2, State Space: 2\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space Box(-inf, inf, (26, 2), float32)\n",
      "state space 2\n",
      "Observation space Box(-inf, inf, (26, 2), float32)\n",
      "state space 2\n"
     ]
    }
   ],
   "source": [
    "all_techs = ['RSI14', 'RSI30', 'RSI3',\n",
    "       'MA200', 'MA50', 'MA20', 'PUT Index', 'RXM Index',\n",
    "       'USGG2YR Index', 'USGG10YR Index', 'MOVE Index', 'VIX Index',\n",
    "       'NWHLSENY Index', 'NWHLSEND Index', 'USGG5YR Index', 'SFFRNEWS Index',\n",
    "       'US10-US2Y', 'macd', 'boll_ub', 'boll_lb',  'cci_30', 'dx_30',\n",
    "       'close_30_sma', 'close_60_sma']\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension,\n",
    "    # \"eco_indicator_list\": eco_indicator_list, \n",
    "    # \"tech_indicator_list\": new_tech_indics, \n",
    "    \"tech_indicator_list\": all_techs, \n",
    "    # \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    # \"cov\": False\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
    "# !FLO New validation set\n",
    "e_validate_gym = StockPortfolioEnv(df = validate, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/floriankockler/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning:\n",
      "\n",
      "You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "env_validate, _ = e_validate_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS, tensorboard_log='/Users/floriankockler/Documents/GitHub.nosync/TrainedModels/TensorboardLogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c_etf',\n",
    "                                total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

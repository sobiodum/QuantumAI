{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Meta/blob/master/tutorials/1-Introduction/FinRL_PortfolioAllocation_NeurIPS_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=10, micro=11, releaselevel='final', serial=0)\n",
      "3.10.11 (main, May 17 2023, 14:30:36) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Option 1:\n",
    "print(sys.version_info)\n",
    "\n",
    "# Option 2:\n",
    "print(sys.version)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "g_emqQCCklVt"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cVCcCalAknGn"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pT8a0fvhA_TW",
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "# %pip install wrds\n",
    "# %pip install swig\n",
    "# %pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bNmvYN9YbU4B"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntfTb0e2bU4C",
    "outputId": "5ee73d83-f253-4150-b806-56a60da1cc77",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FeatureEngineer' from 'preprocessors' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconfig_tickers\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39myahoodownloader\u001b[39;00m \u001b[39mimport\u001b[39;00m YahooDownloader\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocessors\u001b[39;00m \u001b[39mimport\u001b[39;00m FeatureEngineer, data_split\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39menv_portfolio\u001b[39;00m \u001b[39mimport\u001b[39;00m StockPortfolioEnv\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m DRLAgent\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FeatureEngineer' from 'preprocessors' (unknown location)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "from config import config\n",
    "import config_tickers\n",
    "from yahoodownloader import YahooDownloader\n",
    "from preprocessors import FeatureEngineer, data_split\n",
    "from env_portfolio import StockPortfolioEnv\n",
    "from models.models import DRLAgent\n",
    "from plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
    "from data_processor import DataProcessor\n",
    "from processor_yahoofinance import YahooFinanceProcessor\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OlIS2abxkwan"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B8bBq7nsBCfF",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_start_date=\"2004-01-01\"\n",
    "full_end_date=\"2023-07-19\"\n",
    "train_start_date=\"2004-01-01\"\n",
    "train_end_date=\"2015-12-31\"\n",
    "validate_start_date=\"2011-01-01\"\n",
    "validate_end_date=\"2015-12-31\"\n",
    "test_start_date=\"2016-01-01\"\n",
    "test_end_date=\"2023-07-19\"\n",
    "etf_list =[\"SPY\",\"QQQ\",\"IWM\",\"EEM\"]\n",
    "flo_ticker = [\"AAPL\",\"MSFT\", \"NVDA\", \"INTC\",\"GOOGL\",\"TSLA\",\"DAL\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V9UwKwzRbU4l"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# Flo - Add own Indicators\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"etf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdate\u001b[39m.\u001b[39mfactorize()[\u001b[39m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m test\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "test = df.date.factorize()[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.date.factorize()[0]\n",
    "lookrange=252\n",
    "for i in range(lookrange,len(df.index.unique())):\n",
    "  data_lookback = df.loc[i-lookrange:i,:]\n",
    "  print(data_lookback)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qz9K2vul6RmK"
   },
   "source": [
    "## Add covariance matrix as states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhizvNwcrg1n",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# add covariance matrix as states\n",
    "df=df.sort_values(['date','tic'],ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back is one year\n",
    "lookback=252\n",
    "for i in range(lookback,len(df.index.unique())):\n",
    "  data_lookback = df.loc[i-lookback:i,:]\n",
    "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "  return_lookback = price_lookback.pct_change().dropna()\n",
    "  return_list.append(return_lookback)\n",
    "\n",
    "  covs = return_lookback.cov().values \n",
    "  cov_list.append(covs)\n",
    "\n",
    "  \n",
    "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date','tic']).reset_index(drop=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUPwwa13uBQ-",
    "outputId": "2aa538ba-9935-4f69-b8c8-2cf3a3a55e42",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"testcov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "wv3jR1zPrg4g",
    "outputId": "94cef7cc-830b-4c81-da8b-9efba5ad989a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df\n",
    "# df.to_csv(\"etf_for_optuna.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UooHj1OgbU4v"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MQnmN1qdk88I"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrPxgv4eBQ_R",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train = data_split(df, train_start_date, train_end_date)\n",
    "validate = data_split(df, validate_start_date, validate_end_date)\n",
    "#trade = data_split(df, '2020-01-01', config.END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "vU2vXEll0hfk",
    "outputId": "e8c76dfd-2c43-4f60-8eee-a1a4f564eed6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sxQTNjpblAMN"
   },
   "source": [
    "## Environment for Portfolio Allocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlfE-VERbU40",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "class StockPortfolioEnv(gym.Env):\n",
    "    \"\"\"A single stock trading environment for OpenAI gym\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            input data\n",
    "        stock_dim : int\n",
    "            number of unique stocks\n",
    "        hmax : int\n",
    "            maximum number of shares to trade\n",
    "        initial_amount : int\n",
    "            start money\n",
    "        transaction_cost_pct: float\n",
    "            transaction cost percentage per trade\n",
    "        reward_scaling: float\n",
    "            scaling factor for reward, good for training\n",
    "        state_space: int\n",
    "            the dimension of input features\n",
    "        action_space: int\n",
    "            equals stock dimension\n",
    "        tech_indicator_list: list\n",
    "            a list of technical indicator names\n",
    "        turbulence_threshold: int\n",
    "            a threshold to control risk aversion\n",
    "        day: int\n",
    "            an increment number to control date\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _sell_stock()\n",
    "        perform sell action based on the sign of the action\n",
    "    _buy_stock()\n",
    "        perform buy action based on the sign of the action\n",
    "    step()\n",
    "        at each step the agent will return actions, then \n",
    "        we will calculate the reward, and return the next observation.\n",
    "    reset()\n",
    "        reset the environment\n",
    "    render()\n",
    "        use render to return other functions\n",
    "    save_asset_memory()\n",
    "        return account value at each time step\n",
    "    save_action_memory()\n",
    "        return actions/positions at each time step\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, \n",
    "                df,\n",
    "                stock_dim,\n",
    "                hmax,\n",
    "                initial_amount,\n",
    "                transaction_cost_pct,\n",
    "                reward_scaling,\n",
    "                state_space,\n",
    "                action_space,\n",
    "                tech_indicator_list,\n",
    "                turbulence_threshold=None,\n",
    "                lookback=252,\n",
    "                day = 0):\n",
    "        #super(StockEnv, self).__init__()\n",
    "        #money = 10 , scope = 1\n",
    "        self.day = day\n",
    "        self.lookback=lookback\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct =transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "\n",
    "        # action_space normalization and shape is self.stock_dim\n",
    "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,)) \n",
    "        # Shape = (34, 30)\n",
    "        # covariance matrix + technical indicators\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
    "\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)   \n",
    "        self.terminal = False       \n",
    "        self.turbulence_threshold = turbulence_threshold        \n",
    "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # memorize portfolio value each step\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        # memorize portfolio return each step\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # print(self.day)\n",
    "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
    "        # print(actions)\n",
    "\n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = ['daily_return']\n",
    "            plt.plot(df.daily_return.cumsum(),'r')\n",
    "            plt.savefig('results/cumulative_reward.png')\n",
    "            plt.close()\n",
    "            \n",
    "            plt.plot(self.portfolio_return_memory,'r')\n",
    "            plt.savefig('results/rewards.png')\n",
    "            plt.close()\n",
    "\n",
    "            print(\"=================================\")\n",
    "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))           \n",
    "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
    "\n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = ['daily_return']\n",
    "            if df_daily_return['daily_return'].std() !=0:\n",
    "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
    "                       df_daily_return['daily_return'].std()\n",
    "              print(\"Sharpe: \",sharpe)\n",
    "            print(\"=================================\")\n",
    "            \n",
    "            return self.state, self.reward, self.terminal,{}\n",
    "\n",
    "        else:\n",
    "            #print(\"Model actions: \",actions)\n",
    "            # actions are the portfolio weight\n",
    "            # normalize to sum of 1\n",
    "            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
    "            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
    "            #else:\n",
    "            #  norm_actions = actions\n",
    "            weights = self.softmax_normalization(actions) \n",
    "            #print(\"Normalized actions: \", weights)\n",
    "            self.actions_memory.append(weights)\n",
    "            last_day_memory = self.data\n",
    "\n",
    "            #load next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day,:]\n",
    "            self.covs = self.data['cov_list'].values[0]\n",
    "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "            #print(self.state)\n",
    "            # calcualte portfolio return\n",
    "            # individual stocks' return * weight\n",
    "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
    "            # update portfolio value\n",
    "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "\n",
    "            # save into memory\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data.date.unique()[0])            \n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "\n",
    "            # the reward is the new portfolio value or end portfolo value\n",
    "            self.reward = new_portfolio_value \n",
    "            #print(\"Step reward: \", self.reward)\n",
    "            #self.reward = self.reward*self.reward_scaling\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        # load states\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.portfolio_value = self.initial_amount\n",
    "        #self.cost = 0\n",
    "        #self.trades = 0\n",
    "        self.terminal = False \n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]] \n",
    "        return self.state\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "        \n",
    "    def softmax_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator/denominator\n",
    "        return softmax_output\n",
    "\n",
    "    \n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        portfolio_return = self.portfolio_return_memory\n",
    "        #print(len(date_list))\n",
    "        #print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        # date and close price length must match actions length\n",
    "        date_list = self.date_memory\n",
    "        df_date = pd.DataFrame(date_list)\n",
    "        df_date.columns = ['date']\n",
    "        \n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame(action_list)\n",
    "        df_actions.columns = self.data.tic.values\n",
    "        df_actions.index = df_date.date\n",
    "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzD06X0CbU43",
    "outputId": "ab17eecd-2079-4684-a793-0541088b1c00",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stock_dimension \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train\u001b[39m.\u001b[39mtic\u001b[39m.\u001b[39munique())\n\u001b[1;32m      2\u001b[0m state_space \u001b[39m=\u001b[39m stock_dimension\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStock Dimension: \u001b[39m\u001b[39m{\u001b[39;00mstock_dimension\u001b[39m}\u001b[39;00m\u001b[39m, State Space: \u001b[39m\u001b[39m{\u001b[39;00mstate_space\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyg0_ZuVEVQ5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# new_indicators = [\"macds\",\"macdh\",\"rsi_6\",\"rsi_14\",\"close_200_sma\",\"stochrsi\",\"stochrsi_6\",\"trix\",\"vr\",\"wr\",\"cci\",\"atr\",\"supertrend\",\"supertrend_ub\",\"supertrend_lb\",\"dma\",\"pdi\"]\n",
    "all_indics = [\n",
    "        \"macd\",\n",
    "        \"boll_ub\",\n",
    "        \"boll_lb\",\n",
    "        \"rsi_30\",\n",
    "        \"cci_30\",\n",
    "        \"dx_30\",\n",
    "        \"close_30_sma\",\n",
    "        \"close_60_sma\",\n",
    "        \"macds\",\"macdh\",\"rsi_6\",\"rsi_14\",\"close_200_sma\",\"stochrsi\",\"stochrsi_6\",\"trix\",\"vr\",\"wr\",\"cci\",\"atr\",\"supertrend\",\"supertrend_ub\",\"supertrend_lb\",\"dma\",\"pdi\"\n",
    "    ]\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    # \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"tech_indicator_list\": all_indics, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
    "#!FLO New validation set\n",
    "e_validate_gym = StockPortfolioEnv(df = validate, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTlOf8SJGdkl",
    "outputId": "1141154d-5cdc-41ba-f485-4d6e93680049",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "#!FLO New validation set\n",
    "env_validate, _ = e_validate_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPEROPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2eKIu5UPlPnk"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDxU0iCEGdnb",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "agent = DRLAgent(env = env_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hdPe8uzflbXe"
   },
   "source": [
    "### Model 1: **A2C**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!My Best Values\n",
    "best_learning_rate= 3.3798011562953303e-05\n",
    "best_n_steps= 37\n",
    "best_gamma= 0.9912299824042836\n",
    "best_gae_lambda= 0.922570232166817\n",
    "best_ent_coef= 0.07308895723592097\n",
    "best_vf_coef= 0.24495410191752645\n",
    "best_max_grad_norm= 0.4750542295391215\n",
    "\n",
    "agent = DRLAgent(env = env_train)\n",
    "A2C_PARAMS = {\"n_steps\": best_n_steps, \"ent_coef\": best_ent_coef, \"learning_rate\": best_learning_rate, \"gamma\":best_gamma, \"gae_lambda\":best_gae_lambda, \"vf_coef\":best_vf_coef, \"max_grad_norm\":best_max_grad_norm}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS, tensorboard_log='/Users/floriankockler/Documents/GitHub.nosync/TrainedModels/TensorboardLogs/')\n",
    "#OLD\n",
    "\n",
    "# agent = DRLAgent(env = env_train)\n",
    "\n",
    "# A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "# model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS, tensorboard_log='/Users/floriankockler/Documents/GitHub.nosync/TrainedModels/TensorboardLogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1tORf1fIcQ2",
    "outputId": "4a1b885a-ef5d-4dff-f24f-c9468347067b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DazEdrMpIdyz",
    "outputId": "540c591c-e0da-43f8-ae08-989d427a8c79",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c_etf_best_params',\n",
    "                                total_timesteps=50000)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfhURI26P_Nr",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trained_a2c.save('/Users/floriankockler/Documents/GitHub.nosync/TrainedModels//trained_a2c_etf_new2.zip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lvrqTro3lhAh"
   },
   "source": [
    "### Model 2: **PPO**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVXta7jVKMhV",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# agent = DRLAgent(env = env_train)\n",
    "# PPO_PARAMS = {\n",
    "#     \"n_steps\": 2048,\n",
    "#     \"ent_coef\": 0.005,\n",
    "#     \"learning_rate\": 0.0001,\n",
    "#     \"batch_size\": 128,\n",
    "# }\n",
    "# model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5XlUIszKUGx",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# trained_ppo = agent.train_model(model=model_ppo, \n",
    "#                              tb_log_name='ppo',\n",
    "#                              total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmMmk1amUlEm",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# trained_ppo.save('/Users/floriankockler/Documents/GitHub.nosynctrained_ppo_etf_us.zip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "a3Iuv554xYFH"
   },
   "source": [
    "### Model 3: **DDPG**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ojmppgo4LPLz",
    "outputId": "1378d445-f15c-4b2c-833e-1f84e0d78ae2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# agent = DRLAgent(env = env_train)\n",
    "# DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
    "\n",
    "\n",
    "# model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bWt6BIR0LT25",
    "outputId": "1cd63fbf-b7d1-4f3f-e410-77c383fb6406",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "#                              tb_log_name='ddpg',\n",
    "#                              total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4C64xZ1UrQA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# trained_ddpg.save('/content/trained_models/trained_ddpg.zip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SPEXBcm-uBJo"
   },
   "source": [
    "### Model 4: **SAC**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HaWf2QeiLqyO",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# agent = DRLAgent(env = env_train)\n",
    "# SAC_PARAMS = {\n",
    "#     \"batch_size\": 128,\n",
    "#     \"buffer_size\": 100000,\n",
    "#     \"learning_rate\": 0.0003,\n",
    "#     \"learning_starts\": 100,\n",
    "#     \"ent_coef\": \"auto_0.1\",\n",
    "# }\n",
    "\n",
    "# model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgYVPqtKLvi3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# trained_sac = agent.train_model(model=model_sac, \n",
    "#                              tb_log_name='sac',\n",
    "#                              total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nUIx62dUvfF",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# trained_sac.save('/content/trained_models/trained_sac.zip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "iidB5E27dfzh"
   },
   "source": [
    "### Model 5: **TD3**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtRp1mWydkvs",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# agent = DRLAgent(env = env_train)\n",
    "# TD3_PARAMS = {\"batch_size\": 100, \n",
    "#               \"buffer_size\": 1000000, \n",
    "#               \"learning_rate\": 0.001}\n",
    "\n",
    "# model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "argM0DtodmNL",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# trained_td3 = agent.train_model(model=model_td3, \n",
    "#                              tb_log_name='td3',\n",
    "#                              total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGXdd4uEUzCk",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# trained_td3.save('/content/trained_models/trained_td3.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPEROPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "E2Ma6YpTlnuZ"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2019-01-01. We use the A2C model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uas8U6k455sI",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trade = data_split(df,test_start_date, test_end_date)\n",
    "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcGYlhyal205",
    "outputId": "d05ef65a-308e-4e53-c084-848aef8a9f6d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trade.shape\n",
    "trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qq4W9FbSstT7",
    "outputId": "e2fbdf5f-5d3c-4c20-af7a-531e69df04cf",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "#                         environment = e_trade_gym)\n",
    "\n",
    "#my own\n",
    "df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        environment = e_trade_gym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJvj3pXt_Ukg",
    "outputId": "ec912a83-6757-4212-ceeb-af2c8b62c9d2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXMMG_9SdKTu",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_daily_return.to_csv('df_daily_return.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tByVcZ2L9TAJ",
    "outputId": "0e9314e7-9f08-46c3-c1e6-e85263e1160c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# assuming actions_df is your DataFrame\n",
    "ax.stackplot(df_actions.index, df_actions.T, labels=df_actions.columns)\n",
    "\n",
    "ax.set_title('Portfolio Allocation Over Time')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Allocation')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBX3Y68o1vRG",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_actions.to_csv('df_actions.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qFO42LcomPUT"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fAvxipWFmUe8"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oGu3PCa8l6L",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pyfolio import timeseries\n",
    "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
    "perf_func = timeseries.perf_stats \n",
    "perf_stats_all = perf_func( returns=DRL_strat, \n",
    "                              factor_returns=DRL_strat, \n",
    "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_daily_return[\"date\"] = pd.to_datetime(df_daily_return[\"date\"])\n",
    "df_daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hqvwr6SY8l9A",
    "outputId": "fbe5c942-d60b-4ed1-82c9-b27a8ded4243",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"==============DRL Strategy Stats===========\")\n",
    "perf_stats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcWzfa6UloDM",
    "outputId": "71e8aa73-2628-4418-82ca-67a73cfc03c6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"QQQ\", \n",
    "        start = df_daily_return.loc[0,'date'],\n",
    "        end = df_daily_return.loc[len(df_daily_return)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lVVCMVSAmcrI"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fqSEF5PfjjT",
    "outputId": "ad06997e-f90a-4ca1-d924-cd65b0da2a4f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pyfolio\n",
    "%matplotlib inline\n",
    "\n",
    "baseline_df = get_baseline(\n",
    "        ticker='SPY', start=df_daily_return.loc[0,'date'], end=test_end_date\n",
    "    )\n",
    "\n",
    "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "        pyfolio.create_full_tear_sheet(returns = DRL_strat,\n",
    "        \n",
    "                                       benchmark_rets=baseline_returns, set_context=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "te3Ibcj5hUbz"
   },
   "source": [
    "## Min-Variance Portfolio Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VE2eUEuhMKs",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# %pip install PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0NiefM7hHn0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDYDIBH9hcUP",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_tic = trade.tic.unique()\n",
    "unique_trade_date = trade.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trade_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qvk_pJ4iV32",
    "outputId": "1f6add8b-9e6d-412c-e57d-0c18b1bca37d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EICNukJZgnWl",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#calculate_portfolio_minimum_variance\n",
    "portfolio = pd.DataFrame(index = range(1), columns = unique_trade_date)\n",
    "initial_capital = 1000000\n",
    "portfolio.loc[0,unique_trade_date[0]] = initial_capital\n",
    "\n",
    "for i in range(len( unique_trade_date)-1):\n",
    "    df_temp = df[df.date==unique_trade_date[i]].reset_index(drop=True)\n",
    "    df_temp_next = df[df.date==unique_trade_date[i+1]].reset_index(drop=True)\n",
    "    #Sigma = risk_models.sample_cov(df_temp.return_list[0])\n",
    "    #calculate covariance matrix\n",
    "    Sigma = df_temp.return_list[0].cov()\n",
    "    #portfolio allocation\n",
    "    ef_min_var = EfficientFrontier(None, Sigma,weight_bounds=(0, 0.6))\n",
    "    #minimum variance\n",
    "    raw_weights_min_var = ef_min_var.min_volatility()\n",
    "    #get weights\n",
    "    cleaned_weights_min_var = ef_min_var.clean_weights()\n",
    "    \n",
    "    #current capital\n",
    "    cap = portfolio.iloc[0, i]\n",
    "    #current cash invested for each stock\n",
    "    current_cash = [element * cap for element in list(cleaned_weights_min_var.values())]\n",
    "    # current held shares\n",
    "    current_shares = list(np.array(current_cash)\n",
    "                                      / np.array(df_temp.close))\n",
    "    # next time period price\n",
    "    next_price = np.array(df_temp_next.close)\n",
    "    ##next_price * current share to calculate next total account value \n",
    "    portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "    \n",
    "portfolio=portfolio.T\n",
    "portfolio.columns = ['account_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2zmv1ISkpXu",
    "outputId": "1bb43b90-b427-4fb0-dcae-6b9578d5ade2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RmNa7m_f590",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "a2c_cumpod =(df_daily_return.daily_return+1).cumprod()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y821cLKkhCn6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_var_cumpod =(portfolio.account_value.pct_change()+1).cumprod()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5E1X9FFGgqeZ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dji_cumpod =(baseline_returns+1).cumprod()-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih6Jim-blNKY"
   },
   "source": [
    "## Plotly: DRL, Min-Variance, DJIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CISw6s8rbnpZ"
   },
   "outputs": [],
   "source": [
    "# %pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJRH-FX3hTRZ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpfgJcG5PInj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "time_ind = pd.Series(df_daily_return.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CM-NJKa8g7Jp",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trace0_portfolio = go.Scatter(x = time_ind, y = a2c_cumpod, mode = 'lines', name = 'Model Portfolio')\n",
    "\n",
    "trace1_portfolio = go.Scatter(x = time_ind, y = dji_cumpod, mode = 'lines', name = 'DJIA')\n",
    "trace2_portfolio = go.Scatter(x = time_ind, y = min_var_cumpod, mode = 'lines', name = 'Min-Variance')\n",
    "#trace3_portfolio = go.Scatter(x = time_ind, y = ddpg_cumpod, mode = 'lines', name = 'DDPG')\n",
    "#trace4_portfolio = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
    "#trace5_portfolio = go.Scatter(x = time_ind, y = min_cumpod, mode = 'lines', name = 'Min-Variance')\n",
    "\n",
    "#trace4 = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
    "\n",
    "#trace2 = go.Scatter(x = time_ind, y = portfolio_cost_minv, mode = 'lines', name = 'Min-Variance')\n",
    "#trace3 = go.Scatter(x = time_ind, y = spx_value, mode = 'lines', name = 'SPX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35nVVmEuhGa1",
    "outputId": "3d60dbc6-ee34-4565-fadc-57d4417a6c4a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(trace0_portfolio)\n",
    "\n",
    "fig.add_trace(trace1_portfolio)\n",
    "\n",
    "fig.add_trace(trace2_portfolio)\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "        traceorder=\"normal\",\n",
    "        font=dict(\n",
    "            family=\"sans-serif\",\n",
    "            size=15,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        bgcolor=\"White\",\n",
    "        bordercolor=\"white\",\n",
    "        borderwidth=2\n",
    "        \n",
    "    ),\n",
    ")\n",
    "#fig.update_layout(legend_orientation=\"h\")\n",
    "fig.update_layout(title={\n",
    "        #'text': \"Cumulative Return using FinRL\",\n",
    "        'y':0.85,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "#with Transaction cost\n",
    "#fig.update_layout(title =  'Quarterly Trade Date')\n",
    "fig.update_layout(\n",
    "#    margin=dict(l=20, r=20, t=20, b=20),\n",
    "\n",
    "    paper_bgcolor='rgba(1,1,0,0)',\n",
    "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
    "    #xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cumulative Return\",\n",
    "xaxis={'type': 'date', \n",
    "       'tick0': time_ind[0], \n",
    "        'tickmode': 'linear', \n",
    "       'dtick': 86400000.0 *80}\n",
    "\n",
    ")\n",
    "fig.update_xaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
    "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXd-N5Rmh6H7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "def objective(trial):\n",
    "    # Define a search space for hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 10)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.001, 0.1, log=True)\n",
    "    \n",
    "    # Create the A2C model\n",
    "    model_kwargs = {\"n_steps\": n_steps, \"ent_coef\": ent_coef, \"learning_rate\": learning_rate}\n",
    "    model = agent.get_model(model_name=\"a2c\", model_kwargs=model_kwargs, tensorboard_log='/Users/floriankockler/Documents/GitHub.nosync/TrainedModels/TensorboardLogs')\n",
    "\n",
    "    # Train the model\n",
    "    model = agent.train_model(model=model, tb_log_name='a2c_etf', total_timesteps=50000)\n",
    "\n",
    "    # Evaluate the model and get the average reward over 100 steps\n",
    "    mean_reward, _ = evaluate_policy(model, env_train, n_eval_episodes=100)\n",
    "    \n",
    "    return mean_reward  # Optuna maximizes the returned value\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     # Define hyperparameters\n",
    "#     learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "#     n_steps = trial.suggest_int(\"n_steps\", 1, 50)\n",
    "#     gamma = trial.suggest_float(\"gamma\", 0.9, 0.9999)\n",
    "#     gae_lambda = trial.suggest_float(\"gae_lambda\", 0.8, 1.0)\n",
    "#     ent_coef = trial.suggest_float(\"ent_coef\", 1e-6, 0.1, log=True)\n",
    "#     vf_coef = trial.suggest_float(\"vf_coef\", 0.1, 0.9)\n",
    "\n",
    "#     model = A2C('MlpPolicy', env_train, learning_rate=learning_rate, \n",
    "#                 n_steps=n_steps, gamma=gamma, gae_lambda=gae_lambda, \n",
    "#                 ent_coef=ent_coef, vf_coef=vf_coef, verbose=0)\n",
    "\n",
    "#     model.learn(total_timesteps=50000)\n",
    "    \n",
    "#     # Test the trained model\n",
    "#     test_env = e_trade_gym\n",
    "#     test_obs = test_env.reset()\n",
    "#     done = False\n",
    "#     total_reward = 0\n",
    "\n",
    "#     while not done:\n",
    "#         action, _ = model.predict(test_obs)\n",
    "#         test_obs, reward, done, info = test_env.step(action)\n",
    "#         total_reward += reward\n",
    "    \n",
    "#     return total_reward  # Objective value\n",
    "\n",
    "# # Optimize\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # Display the best trial\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\" Value: \", trial.value)\n",
    "# print(\" Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 5, 50)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.9, 0.9999, log=True)\n",
    "    gae_lambda = trial.suggest_float(\"gae_lambda\", 0.8, 1.0, log=True)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.001, 0.1, log=True)\n",
    "    vf_coef = trial.suggest_float(\"vf_coef\", 0.1, 0.5, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.1, 0.6, log=True)\n",
    "\n",
    "    model = A2C(\n",
    "        \"MlpPolicy\",\n",
    "        env_train,\n",
    "        learning_rate=learning_rate,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        gae_lambda=gae_lambda,\n",
    "        ent_coef=ent_coef,\n",
    "        vf_coef=vf_coef,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "        verbose=0,\n",
    "    )\n",
    "    model.learn(total_timesteps=20000)\n",
    "\n",
    "    _, rewards = evaluate_policy(model, e_trade_gym, n_eval_episodes=5, return_episode_rewards=True)\n",
    "    return np.mean(rewards)\n",
    "def save_checkpoint(study, trial):\n",
    "    joblib.dump(study, 'checkpoint.pkl')\n",
    "# Optimize\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Check if a checkpoint exists\n",
    "try:\n",
    "    study = joblib.load('checkpoint.pkl')\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Display the best trial\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna for A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "def objective(trial):\n",
    "    # hyperparameters\n",
    "    # gamma = trial.suggest_categorical('gamma', [0.99, 0.995, 0.999, 0.9999])\n",
    "    # n_steps = trial.suggest_categorical('n_steps', [5, 10, 20, 50, 100])\n",
    "    # ent_coef = trial.suggest_loguniform('ent_coef', 0.00001, 0.1)\n",
    "    # learning_rate = trial.suggest_loguniform('learning_rate', 0.00001, 0.1)\n",
    "    # vf_coef = trial.suggest_loguniform('vf_coef', 0.1, 0.9)\n",
    "    # max_grad_norm = trial.suggest_categorical('max_grad_norm', [0.3, 0.5, 0.7, 0.9, 1])\n",
    "    # gae_lambda = trial.suggest_categorical('gae_lambda', [0.9, 0.92, 0.95, 0.98, 1.0])\n",
    "    #Hier mit floating, dauert länger\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 5, 50)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.9, 0.9999, log=True)\n",
    "    gae_lambda = trial.suggest_float(\"gae_lambda\", 0.8, 1.0, log=True)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.001, 0.1, log=True)\n",
    "    vf_coef = trial.suggest_float(\"vf_coef\", 0.1, 0.5, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.1, 0.6, log=True)\n",
    "    \n",
    "    # Create the model\n",
    "    model = A2C(\"MlpPolicy\", env_train, \n",
    "                gamma=gamma, \n",
    "                n_steps=n_steps, \n",
    "                ent_coef=ent_coef, \n",
    "                learning_rate=learning_rate, \n",
    "                vf_coef=vf_coef,\n",
    "                max_grad_norm=max_grad_norm,\n",
    "                gae_lambda=gae_lambda,\n",
    "                verbose=0)\n",
    "\n",
    "    # Here I'm supposing your environment has attributes reward_scaling, lookback and transaction_cost_pct,\n",
    "    # which you would like to optimize. Replace with the attributes of your own environment.\n",
    "    env_train.reward_scaling = trial.suggest_uniform(\"reward_scaling\", 0.1, 10)\n",
    "    env_train.lookback = trial.suggest_int(\"lookback\", 100, 500)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=50000)\n",
    "\n",
    "    # Test the model and return the mean reward\n",
    "    mean_reward, _ = evaluate_policy(model, e_trade_gym, n_eval_episodes=10)\n",
    "    return mean_reward\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Best trial:')\n",
    "trial_ = study.best_trial\n",
    "\n",
    "print(f'Value: {trial_.value}')\n",
    "\n",
    "print('Best hyperparameters:')\n",
    "for key, value in trial_.params.items():\n",
    "    print(f'    {key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lvrqTro3lhAh",
    "a3Iuv554xYFH",
    "SPEXBcm-uBJo",
    "iidB5E27dfzh"
   ],
   "name": "FinRL_PortfolioAllocation_NeurIPS_2020.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0cd912b5b8ef2e2cf6ba30a360471b623d2891ab42b88478be3d571482cb392e"
  },
  "kernelspec": {
   "display_name": "PyCharm (FinRL)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
